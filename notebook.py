# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12a2ifaKkhp-3bD5h0J47Mu_jD9c0RN15

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Jaya Jaya Maju

- Nama        : Labiba Adinda Zahwana
- Email       : labibaadinda11@gmail.com

# Persiapan

## Import Library
Import library / package yang dibutuhkan
"""

!pip install catboost

"""Pada bagian ini, import berbagai pustaka dan paket yang dibutuhkan untuk analisis dan pembuatan model machine learning, seperti pandas untuk manipulasi data, matplotlib dan seaborn untuk visualisasi, scikit-learn untuk pembelajaran mesin, serta pustaka lainnya seperti catboost dan lightgbm untuk model pembelajaran yang lebih lanjut."""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import chi2_contingency
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
import lightgbm as lgb
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score
import joblib

"""## Import Dataset"""

df = pd.read_csv("https://raw.githubusercontent.com/labibaadinda/dashboard-data-science-project-1/refs/heads/main/data/employee_data.csv")

"""# Data Understanding

## Univariate Data Analysis

### Univariate Data Analysis - Dataset
"""

df.head()

df.info()

df.isnull().sum()

"""**Insight Dataset Karyawan Perusahaan Jaya Jaya Maju**

Dataset ini berisi data karyawan yang bekerja di perusahaan **Jaya Jaya Maju**, dengan 35 fitur dan 1470 entri data.

1. **EmployeeId**

   * Nomor identifikasi unik karyawan.
   * Bertipe integer.
   * Tidak terdapat missing value.

2. **Age**

   * Usia karyawan.
   * Bertipe integer.
   * Tidak terdapat missing value.

3. **Attrition**

   * Menunjukkan apakah karyawan keluar (1) atau masih bekerja (0).
   * Bertipe float.
   * Terdapat **missing value**, perlu penanganan terhadap missing value.

4. **BusinessTravel**

   * Frekuensi perjalanan bisnis karyawan.
   * Bertipe string.
   * Tidak terdapat missing value.

5. **DailyRate**

   * Gaji harian karyawan.
   * Bertipe integer.
   * Tidak terdapat missing value.

6. **Department**

   * Nama departemen tempat karyawan bekerja.
   * Bertipe string.
   * Tidak terdapat missing value.

7. **DistanceFromHome**

   * Jarak dari rumah karyawan ke kantor dalam kilometer.
   * Bertipe integer.
   * Tidak terdapat missing value.

8. **Education**

   * Menunjukkan tingkat pendidikan karyawan.
   * Bertipe integer (1-5).
   * Tidak terdapat missing value.

9. **EducationField**

   * Jurusan dalam pendidikan karyawan.
   * Bertipe string.
   * Tidak terdapat missing value.

10. **EmployeeCount**

    * Menyatakan jumlah karyawan (selalu bernilai 1).
    * Bertipe integer.
    * Tidak terdapat missing value.

11. **EnvironmentSatisfaction**

    * Kepuasan terhadap lingkungan kerja.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

12. **Gender**

    * Jenis kelamin karyawan (Male/Female).
    * Bertipe string.
    * Tidak terdapat missing value.

13. **HourlyRate**

    * Gaji per jam.
    * Bertipe integer.
    * Tidak terdapat missing value.

14. **JobInvolvement**

    * Tingkat keterlibatan karyawan dalam pekerjaan.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

15. **JobLevel**

    * Level jabatan karyawan.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

16. **JobRole**

    * Peran atau jabatan dalam pekerjaan.
    * Bertipe string.
    * Tidak terdapat missing value.

17. **JobSatisfaction**

    * Kepuasan kerja karyawan terhadap pekerjaan mereka.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

18. **MaritalStatus**

    * Status pernikahan karyawan (Single, Married, Divorced).
    * Bertipe string.
    * Tidak terdapat missing value.

19. **MonthlyIncome**

    * Penghasilan bulanan karyawan.
    * Bertipe integer.
    * Tidak terdapat missing value.

20. **MonthlyRate**

    * Gaji bulanan karyawan.
    * Bertipe integer.
    * Tidak terdapat missing value.

21. **NumCompaniesWorked**

    * Jumlah perusahaan tempat karyawan bekerja sebelumnya.
    * Bertipe integer.
    * Tidak terdapat missing value.

22. **Over18**

    * Menyatakan apakah karyawan berusia di atas 18 tahun.
    * Bertipe string (Yes/No).
    * Tidak terdapat missing value.

23. **OverTime**

    * Menunjukkan apakah karyawan sering bekerja lembur (Yes/No).
    * Bertipe string.
    * Tidak terdapat missing value.

24. **PercentSalaryHike**

    * Persentase kenaikan gaji karyawan dari tahun sebelumnya.
    * Bertipe integer.
    * Tidak terdapat missing value.

25. **PerformanceRating**

    * Tingkat kinerja karyawan (1-4).
    * Bertipe integer.
    * Tidak terdapat missing value.

26. **RelationshipSatisfaction**

    * Kepuasan karyawan terhadap hubungan dengan rekan kerja.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

27. **StandardHours**

    * Jam kerja standar karyawan.
    * Bertipe integer.
    * Tidak terdapat missing value.

28. **StockOptionLevel**

    * Menunjukkan level opsi saham yang diterima karyawan.
    * Bertipe integer (0-3).
    * Tidak terdapat missing value.

29. **TotalWorkingYears**

    * Total pengalaman kerja karyawan dalam tahun.
    * Bertipe integer.
    * Tidak terdapat missing value.

30. **TrainingTimesLastYear**

    * Jumlah pelatihan yang diikuti karyawan pada tahun sebelumnya.
    * Bertipe integer.
    * Tidak terdapat missing value.

31. **WorkLifeBalance**

    * Tingkat keseimbangan antara pekerjaan dan kehidupan pribadi.
    * Bertipe integer (1-4).
    * Tidak terdapat missing value.

32. **YearsAtCompany**

    * Jumlah tahun karyawan bekerja di perusahaan ini.
    * Bertipe integer.
    * Tidak terdapat missing value.

33. **YearsInCurrentRole**

    * Jumlah tahun karyawan berada di posisi jabatan saat ini.
    * Bertipe integer.
    * Tidak terdapat missing value.

34. **YearsSinceLastPromotion**

    * Jumlah tahun sejak karyawan terakhir dipromosikan.
    * Bertipe integer.
    * Tidak terdapat missing value.

35. **YearsWithCurrManager**

    * Jumlah tahun karyawan bekerja dengan manajer saat ini.
    * Bertipe integer.
    * Tidak terdapat missing value.

---

**Langkah Berikutnya**:

1. **Penanganan Missing Values**: Perbaiki missing values pada kolom **Attrition** untuk analisis lebih lanjut.
2. **Analisis Pengaruh Fitur Terhadap Attrition**: Tinjau fitur-fitur seperti **Age**, **MonthlyIncome**, **JobSatisfaction**, dan **OverTime** yang berpotensi memengaruhi **attrition**.
3. **Model Prediksi**: Bangun model untuk memprediksi **attrition** menggunakan algoritma klasifikasi seperti Logistic Regression atau Random Forest.

### Univariate Data Analysis - Fitur Numerikal
"""

numeric_col = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
print(numeric_col)

df.select_dtypes(include=['int64', 'float64']).shape

df.describe()

# Ukuran grid
rows, cols = 5, 6
fig, axes = plt.subplots(rows, cols, figsize=(24, 20))
axes = axes.flatten()

# Loop setiap fitur numerik dan plot
for i, col in enumerate(numeric_col):
    sns.histplot(df[col], kde=True, ax=axes[i], bins=30, color='pink')
    axes[i].set_title(f'Distribusi {col}', fontsize=16, color='darkgray')
    axes[i].set_xlabel('')
    axes[i].set_ylabel('')

# Jika jumlah kolom < grid, matikan subplot kosong
for j in range(len(numeric_col), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# Ukuran grid
rows, cols = 5, 6
fig, axes = plt.subplots(rows, cols, figsize=(24, 20))
axes = axes.flatten()

# Plot setiap fitur numerik
for i, col in enumerate(numeric_col):
    sns.boxplot(y=df[col], ax=axes[i], color='pink')
    axes[i].set_title(f'Box Plot: {col}')
    axes[i].set_xlabel('')
    axes[i].set_ylabel('')

# Hapus sisa subplot kosong
for j in range(len(numeric_col), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""**Insight:**

Berdasarkan eksplorasi distribusi data numerik melalui histogram dan boxplot, beberapa temuan penting diperoleh sebagai berikut:

1. Fitur yang Tidak Informatif
   > Beberapa fitur tidak memberikan variasi atau informasi karena nilai-nilainya tetap (konstan) atau hanya berisi ID unik. Fitur-fitur ini dapat dihapus untuk menyederhanakan dataset.

2. Distribusi Data
   > Sebagian besar fitur numerik menunjukkan distribusi skewed (terdistrusi miring), yaitu:
   - Skewed right (positif): Fitur-fitur seperti Age, DistanceFromHome, JobLevel, MonthlyIncome, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, dan YearsWithCurrManager.
   - Skewed left (negatif): Fitur-fitur seperti EnvironmentSatisfaction, JobInvolvement, dan WorkLifeBalance.
   - Hanya beberapa fitur yang mendekati distribusi normal, seperti Age, DailyRate, dan HourlyRate.

3. Keberadaan Outlier
   > Terdapat outlier pada beberapa fitur, terutama yang berkaitan dengan durasi kerja dan penghasilan, seperti MonthlyIncome, NumCompaniesWorked, TotalWorkingYears, YearsAtCompany, dan YearsSinceLastPromotion.
   Namun, beberapa fitur seperti DailyRate, HourlyRate, Education, JobInvolvement, dan WorkLifeBalance tidak menunjukkan adanya outlier.

4. Imbalance Kelas
   > Fitur Attrition menunjukkan adanya ketidakseimbangan kelas, di mana sebagian besar data memiliki label 0. Hal ini perlu ditangani agar model yang dibangun dengan dataset ini tidak hanya memprediksi kelas mayoritas. Teknik yang bisa diterapkan untuk menangani masalah ini adalah resampling.

### Univariate Data Analysis - Fitur Kategorikal
"""

categorical_col = df.select_dtypes(include=['object']).columns.tolist()
print(categorical_col)

df.select_dtypes(include=['object']).shape[1]

# Atur ukuran grid
rows, cols = 4, 3
fig, axes = plt.subplots(rows, cols, figsize=(15, 20))
axes = axes.flatten()

# Loop setiap fitur kategorikal
for i, col in enumerate(categorical_col):
    ax = axes[i]
    sns.countplot(x=col, data=df, hue=col, palette='pastel', legend=False, ax=ax)

    # Tambahkan angka di atas tiap batang
    for p in ax.patches:
        height = p.get_height()
        ax.text(p.get_x() + p.get_width() / 2., height + 1, f'{int(height)}',
                ha='center', va='bottom', fontsize=9)

    ax.set_title(f'Distribusi {col}')
    ax.set_xlabel('')
    ax.set_ylabel('')
    ax.tick_params(axis='x', rotation=45)

# Jika fitur lebih sedikit dari jumlah subplot, hapus sisa subplot kosong
for j in range(len(categorical_col), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""**Insight:**

1. **BusinessTravel**
   Sebagian besar karyawan jarang melakukan perjalanan bisnis, dengan 1043 karyawan yang memilih opsi **Travel\_Rarely**.

2. **Department**
   Mayoritas karyawan bekerja di **Research & Development** (961 orang), diikuti oleh **Sales** (446 orang), sedangkan **Human Resources** memiliki jumlah karyawan paling sedikit, yaitu 63 orang.

3. **EducationField**
   Karyawan dengan latar belakang pendidikan di bidang **Life Sciences** (606 orang) dan **Medical** (512 orang) mendominasi, menunjukkan bahwa mayoritas karyawan berasal dari sektor sains dan kesehatan.

4. **Gender**
   Jumlah karyawan laki-laki (882 orang) lebih banyak dibandingkan perempuan (588 orang).

5. **JobRole**
   Jabatan terbanyak adalah **Sales Executive** (326 orang), **Research Scientist** (292 orang), dan **Laboratory Technician** (259 orang).

6. **MaritalStatus**
   Mayoritas karyawan sudah menikah (673 orang), diikuti oleh yang belum menikah (470 orang) dan yang bercerai (327 orang).

7. **Over18**
   Semua entri memiliki nilai **Y**, yang menunjukkan bahwa seluruh karyawan berusia di atas 18 tahun. Fitur ini redundan dan dapat dihapus karena tidak memberikan informasi atau pola yang berguna.

8. **OverTime**
   Sebagian besar karyawan tidak melakukan lembur, dengan 1054 orang memilih untuk tidak lembur, sementara 416 orang sering lembur.

---

**Saran:**

1. **Encoding**: Data kategorikal perlu di-encode agar dapat digunakan dalam proses pelatihan model.
2. **Fitur Selection**: Lakukan pemilihan fitur dengan menghapus fitur yang tidak relevan dan memilih fitur berdasarkan kekuatan pengaruhnya terhadap target variabel **attrition**.

## Multivariate Data Analysis

### Korelasi Data Numerik
"""

# Ambil hanya fitur numerik
df_numerik = df.select_dtypes(include=['int64', 'float64'])

# Hitung korelasi
corr_matrix = df_numerik.corr()

# Tampilkan heatmap
plt.figure(figsize=(14, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5)
plt.title("Matriks Korelasi Fitur Numerik")
plt.tight_layout()
plt.show()

"""Heatmap yang tersebut adalah matriks korelasi antar fitur numerik. Berikut beberapa wawasan yang dapat diambil:

1. Korelasi Positif yang Kuat:

   - `MonthlyRate` dan `PerformanceRating` memiliki korelasi positif yang tinggi (0.77). Ini menunjukkan bahwa gaji bulanan yang lebih tinggi terkait dengan penilaian kinerja yang lebih baik.
   - `YearsAtCompany` dan `TotalWorkingYears` juga menunjukkan korelasi yang kuat (0.68), yang mengindikasikan bahwa karyawan dengan masa kerja lebih lama di perusahaan cenderung memiliki pengalaman kerja yang lebih banyak secara keseluruhan.
   - `YearsInCurrentRole` dan `TrainingTimesLastYear` memiliki korelasi positif sedang (0.46), yang menunjukkan bahwa karyawan dengan masa jabatan lebih lama dalam peran mereka saat ini cenderung mengikuti lebih banyak pelatihan dalam setahun terakhir.

2. Korelasi Negatif:

   - `DistanceFromHome` dan `EmployeeCount` menunjukkan korelasi negatif ringan (-0.22). Karyawan yang tinggal lebih jauh dari kantor mungkin lebih jarang bekerja dalam kelompok besar (yang ditunjukkan oleh `EmployeeCount`).
   - `JobSatisfaction` dan `JobLevel` memiliki korelasi negatif kecil (-0.51). Ini menunjukkan bahwa semakin tinggi level jabatan, semakin rendah tingkat kepuasan pekerjaan, meskipun korelasi ini sedang.

3. Relasi Lain yang Perlu Diperhatikan:

   - `Attrition` dan `Age` menunjukkan korelasi negatif kecil (-0.17), yang berarti karyawan yang lebih tua cenderung lebih sedikit meninggalkan perusahaan, meskipun efek ini cukup lemah.
   - `JobLevel` memiliki korelasi negatif dengan `EnvironmentSatisfaction` (-0.31), yang menunjukkan bahwa karyawan di level jabatan yang lebih tinggi cenderung melaporkan kepuasan lingkungan kerja yang sedikit lebih rendah.
   - `YearsInCurrentRole` dan `JobLevel` memiliki korelasi positif sedang (0.39), yang menunjukkan bahwa karyawan di level jabatan yang lebih tinggi cenderung memiliki masa jabatan yang lebih lama dalam peran mereka saat ini.


"""

# Ambil fitur numerik
df_numerik = df.select_dtypes(include=['int64', 'float64'])

# Hitung korelasi antar fitur numerik, lalu ambil korelasi terhadap 'Attrition'
# corr_with_attrition = df_numerik.corr()['Attrition'].sort_values(ascending=False)
corr_with_attrition = df_numerik.corr()[['Attrition']].sort_values(by='Attrition', ascending=False)

# Tampilkan hasil
# print(corr_with_attrition)

plt.figure(figsize=(6, 10))
sns.heatmap(corr_with_attrition, annot=True, cmap='coolwarm', center=0, fmt=".2f")
plt.title('Korelasi Fitur Numerik terhadap Attrition')
plt.tight_layout()
plt.show()

"""Hasil Analisis Korelasi Fitur Numerik terhadap Attrition :

1. **Korelasi Positif Terkuat**:

   * **DistanceFromHome** (0.08) menunjukkan bahwa semakin jauh jarak dari rumah, sedikit lebih besar kemungkinan karyawan untuk keluar, meski hubungannya lemah.

2. **Korelasi Negatif Terkuat**:

   * **TotalWorkingYears** (-0.18), **Age** (-0.17), dan **JobLevel** (-0.16) menunjukkan bahwa semakin sedikit pengalaman kerja, semakin muda usia, dan semakin rendah level pekerjaan, kemungkinan karyawan untuk keluar lebih besar.
   * **YearsAtCompany** (-0.14) dan **YearsInCurrentRole** (-0.16) juga memiliki korelasi negatif, artinya semakin lama karyawan berada di perusahaan atau di posisi saat ini, semakin kecil kemungkinan untuk keluar.

3. **Korelasi Moderat**:

   * **EnvironmentSatisfaction** (-0.13), **JobSatisfaction** (-0.09), dan **WorkLifeBalance** (-0.06) menunjukkan bahwa karyawan dengan tingkat kepuasan yang lebih tinggi cenderung tidak keluar.

4. **Korelasi Lemah**:

   * Banyak fitur lain seperti **HourlyRate**, **PerformanceRating**, dan **PercentSalaryHike** memiliki korelasi yang sangat lemah dengan attrition, artinya faktor-faktor ini kurang berpengaruh terhadap keputusan karyawan untuk keluar.

Secara keseluruhan, faktor usia, pengalaman kerja, dan kepuasan kerja menjadi indikator penting terkait dengan tingkat attrition karyawan.

### Korelasi data kategorik
"""

kategorik_fitur = df.select_dtypes(include=['object']).columns

# Tentukan ukuran grid
rows, cols = 4, 3  # Sesuaikan dengan jumlah fitur
fig, axes = plt.subplots(rows, cols, figsize=(18, 20))
axes = axes.flatten()  # Biar bisa diakses dengan indeks

# Loop untuk setiap fitur
for i, col in enumerate(kategorik_fitur):
    ax = axes[i]
    sns.countplot(x=col, data=df, hue='Attrition', palette='pastel', ax=ax)
    ax.set_title(f'Attrition vs {col}', fontsize=11)
    ax.set_xlabel('')
    ax.set_ylabel('')
    ax.tick_params(axis='x', rotation=90)

# Hilangkan sisa subplot kosong jika jumlah fitur < jumlah subplot
for j in range(len(kategorik_fitur), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

"""Dari visualisasi tsb, berikut adalah beberapa analisis yang dapat ditarik:

1. **Attrition vs Business Travel**:

   * Karyawan yang melakukan perjalanan bisnis sering menunjukkan tingkat attrition yang lebih rendah dibandingkan dengan yang tidak sering bepergian. Ini bisa menunjukkan bahwa perjalanan bisnis mungkin berhubungan dengan lebih banyak keterlibatan atau insentif yang mengurangi kecenderungan keluar dari perusahaan.

2. **Attrition vs Department**:

   * Departemen **Research & Development** menunjukkan tingkat attrition yang lebih tinggi, sementara **Human Resources** dan **Sales** memiliki lebih sedikit karyawan yang keluar. Hal ini bisa disebabkan oleh ketegangan atau beban kerja yang lebih tinggi di beberapa departemen seperti Research & Development.

3. **Attrition vs Education Field**:

   * Karyawan dengan latar belakang pendidikan **Life Sciences** memiliki tingkat attrition yang lebih tinggi, sementara mereka yang memiliki latar belakang pendidikan di bidang **Technical Degree** lebih cenderung tetap bekerja di perusahaan. Hal ini mungkin berkaitan dengan kesempatan karir atau kepuasan kerja yang berbeda berdasarkan bidang pendidikan.

4. **Attrition vs Gender**:

   * Secara keseluruhan, lebih banyak **pria** yang bertahan di perusahaan dibandingkan **wanita**, meskipun perbedaan ini tidak terlalu besar. Perlu dicermati lebih lanjut apakah ada faktor lain, seperti peran gender dalam pekerjaan, yang mempengaruhi keputusan attrition.

5. **Attrition vs Job Role**:

   * **Sales Executive** dan **Healthcare Representative** tampaknya memiliki tingkat attrition yang lebih tinggi dibandingkan dengan jabatan lain seperti **Manager** atau **Research Scientist**. Mungkin ada faktor stres pekerjaan atau ketidakpuasan yang lebih tinggi pada posisi-posisi ini.

6. **Attrition vs Marital Status**:

   * Karyawan yang **menikah** memiliki tingkat attrition yang lebih rendah dibandingkan dengan yang **lajang** atau **cerai**. Ini mungkin menunjukkan stabilitas yang lebih tinggi di rumah tangga yang berpengaruh pada keputusan untuk tetap tinggal di perusahaan.

7. **Attrition vs Over18**:

   * Sebagian besar karyawan yang lebih dari 18 tahun menunjukkan sedikitnya tingkat attrition, yang mungkin menunjukkan bahwa umur atau masa kerja memiliki pengaruh pada keputusan untuk keluar dari perusahaan.

8. **Attrition vs Overtime**:

   * Karyawan yang bekerja lembur cenderung memiliki tingkat attrition yang lebih rendah dibandingkan dengan yang tidak bekerja lembur. Ini bisa menunjukkan bahwa pekerjaan lembur mungkin memberikan insentif atau penghargaan yang mengurangi keinginan untuk keluar dari perusahaan.

Kesimpulannya, beberapa faktor seperti perjalanan bisnis, pekerjaan lembur, status pernikahan, dan departemen tempat bekerja dapat mempengaruhi tingkat attrition.

"""

# Fungsi Cramér's V
def cramers_v(x, y):
    table = pd.crosstab(x, y)
    chi2, _, _, _ = chi2_contingency(table)
    n = table.sum().sum()
    phi2 = chi2 / n
    r, k = table.shape
    # Koreksi bias untuk tabel tidak persegi
    phi2_corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))
    r_corr = r - ((r-1)**2)/(n-1)
    k_corr = k - ((k-1)**2)/(n-1)
    return np.sqrt(phi2_corr / min((k_corr-1), (r_corr-1)))

# Ambil fitur kategorikal (kecuali target)
kategorik_fitur = df.select_dtypes(include=['object']).columns
kategorik_fitur = [col for col in kategorik_fitur if col != 'Attrition']

# Simpan hasil
hasil_chi2 = []

for col in kategorik_fitur:
    table = pd.crosstab(df['Attrition'], df[col])
    chi2, p, dof, expected = chi2_contingency(table)
    v = cramers_v(df[col], df['Attrition'])

    hasil_chi2.append({
        'Fitur': col,
        'Chi2': chi2,
        'p-value': p,
        "Cramér's V": v
    })

# Buat DataFrame
hasil_df = pd.DataFrame(hasil_chi2)

# Urutkan berdasarkan p-value
hasil_df = hasil_df.sort_values('p-value')

# Tampilkan
print(hasil_df)

"""Untuk menganalisis hubungan antara fitur kategorikal dengan Attrition, dapat dilakukan uji Chi-Square dan perhitungan Cramer's V. Uji Chi-Square digunakan untuk menentukan apakah terdapat hubungan antara fitur-fitur tersebut, sementara Cramer's V digunakan untuk mengukur kekuatan hubungan yang ada.

**Insight:**

**Analisis Chi2 & p-value:**

* `OverTime`, `JobRole`, `MaritalStatus`, dan `BusinessTravel` memiliki nilai p yang sangat kecil (< 0.05), yang berarti hubungan antara fitur-fitur ini dengan `Attrition` signifikan secara statistik.
* `Department` dan `EducationField` memiliki nilai p yang mendekati rentang 0.05-0.1, yang mengindikasikan bahwa hubungan ini dapat dianggap lemah.
* `Gender` dan `Over18` memiliki nilai p > 0.05, yang berarti tidak ada bukti yang kuat untuk menunjukkan bahwa kedua fitur ini memengaruhi `Attrition`.

**Analisis Cramér's V:**

* `OverTime` memiliki interpretasi hubungan yang sedang (0.10-0.20), yang berarti ada hubungan yang signifikan dan cukup kuat dengan `Attrition`. Karyawan yang lembur cenderung lebih banyak yang resign.
* `JobRole` juga menunjukkan hubungan sedang (0.10-0.20), yang berarti beberapa peran kerja lebih rentan terhadap `Attrition`.
* `MaritalStatus` memiliki interpretasi hubungan lemah hingga sedang (0.18), yang berarti status pernikahan memengaruhi `Attrition`, meskipun tidak terlalu kuat.
* `BusinessTravel` menunjukkan hubungan lemah (0.10), namun tetap ada hubungan yang berarti. Ini menunjukkan bahwa sering bepergian mungkin memengaruhi `Attrition`.
* `EducationField` dan `Department` memiliki interpretasi hubungan yang sangat lemah, yang berarti kedua fitur ini tidak memberikan pengaruh yang signifikan terhadap `Attrition`.
* `Gender` tidak memiliki hubungan yang berarti dengan `Attrition`.
* `Over18` memiliki nilai konstan sehingga tidak dapat dihitung hubungannya.

**Catatan:**

* Pertimbangkan untuk menghapus fitur yang tidak relevan atau tidak memiliki hubungan dengan `Attrition`, seperti `Gender` dan `Over18`.
* Lakukan evaluasi lebih lanjut untuk pemilihan fitur terhadap fitur dengan interpretasi yang sangat rendah, seperti `BusinessTravel`, `EducationField`, dan `Department`.

# Data Preparation
"""

df_cleaned = df.dropna(subset=['Attrition'])

df_cleaned['Attrition'] = df_cleaned['Attrition'].astype('int64')

df_cleaned.info()

categorical_features = ['OverTime', 'JobRole', 'MaritalStatus', 'BusinessTravel', 'Department']

numerical_features = ['TotalWorkingYears', 'Age', 'JobLevel', 'StockOptionLevel', 'MonthlyIncome', 'YearsInCurrentRole',
                          'YearsWithCurrManager', 'JobInvolvement', 'YearsAtCompany', 'YearsSinceLastPromotion']

X = df_cleaned[categorical_features + numerical_features]
y = df_cleaned['Attrition']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(drop='first'), categorical_features)  # drop='first' untuk hindari dummy trap
    ]
)

X_processed = preprocessor.fit_transform(X)

ohe_columns = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
all_columns = numerical_features + list(ohe_columns)

df_final = pd.DataFrame(X_processed.toarray() if hasattr(X_processed, "toarray") else X_processed, columns=all_columns)
df_final['Attrition'] = y.values

df_final

X = df_final.drop('Attrition', axis=1)  # Semua fitur
y = df_final['Attrition']               # Target

# split data dengan rasion 80:20
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Jumlah data latih:", X_train.shape[0])
print("Jumlah data uji:", X_test.shape[0])

smote = SMOTE(random_state=42)

X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

print("Jumlah data latih sebelum SMOTE:", len(y_train))
print("Jumlah data latih sesudah SMOTE:", len(y_train_smote))
print("Distribusi kelas setelah SMOTE:\n", y_train_smote.value_counts())

# Inisialisasi
model = RandomForestClassifier(random_state=42)

# Inisialisasi RFE - pilih jumlah fitur yang ingin dipertahankan
rfe = RFE(estimator=model, n_features_to_select=10)

# fit ke data SMOTE yang sudah siap
rfe.fit(X_train_smote, y_train_smote)

# ambil nama-nama fitur yang dipilih
selected_features = X_train_smote.columns[rfe.support_]

# print hasil
print("Fitur terpilih oleh RFE:")
print(selected_features.tolist())

selected_features = X_train_smote.columns[rfe.support_]

X_train_selected = X_train_smote[selected_features]
X_test_selected = X_test[selected_features]

"""# Modeling

Pada tahapan ini, model yang digunakan untuk memprediksi apakah karyawan akan melakukan `attrition` (resign) dari perusahaan Jaya Jaya Maju antara lain `Random Forest`, `CatBoost`, dan `LightGBM`.

1. **Random Forest** dipilih karena kemampuannya untuk menangani data non-linear dan interaksi antar fitur secara otomatis, serta sifatnya yang tahan terhadap overfitting, membuatnya cocok untuk menangani dataset yang besar dan kompleks.

2. **CatBoost** merupakan algoritma boosting yang sangat baik dalam menangani data kategorikal dan memiliki kemampuan untuk mengurangi masalah overfitting. Model ini sering memberikan performa yang lebih baik dalam berbagai kasus dan lebih efisien dibandingkan dengan model boosting lainnya.

3. **LightGBM** adalah model boosting lainnya yang terkenal dengan kecepatan komputasi yang tinggi dan kemampuan untuk menangani dataset besar dengan banyak fitur. LightGBM cenderung memberikan hasil yang sangat baik dalam memprediksi target variabel pada dataset yang besar dan kompleks.

Ketiga model ini akan dilatih dan dievaluasi untuk memperoleh model yang paling optimal dalam memprediksi **Attrition**.

"""

models = {
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100, max_depth=None, min_samples_split=2),
    'CatBoost': CatBoostClassifier(random_state=42, verbose=0, iterations=1000, learning_rate=0.1, depth=6),
    'LightGBM': lgb.LGBMClassifier(random_state=42, num_leaves=31, learning_rate=0.05, n_estimators=100, verbose=-1)
}

trained_models = {}
predictions = {}

# Train semua model
for name, model in models.items():
    model.fit(X_train_selected, y_train_smote)
    trained_models[name] = model
    predictions[name] = model.predict(X_test_selected)

"""# Evaluation"""

# Simpan hasil evaluasi ke dalam tabel
evaluation_results = []

for name, y_pred in predictions.items():
    report = classification_report(y_test, y_pred, output_dict=True)

    evaluation_results.append({
        "Model": name,
        "Accuracy": report['accuracy'],
        "Precision": report['1']['precision'],
        "Recall": report['1']['recall'],
        "F1-Score": report['1']['f1-score']
    })

# Ubah menjadi DataFrame
comparison_df = pd.DataFrame(evaluation_results)

# Tampilkan
print(comparison_df)

# Plot confusion matrix untuk setiap model
fig, axes = plt.subplots(1, len(models), figsize=(18, 5))

for i, (name, model) in enumerate(models.items()):
    cm = confusion_matrix(y_test, predictions[name])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])
    axes[i].set_title(f'{name}')
    axes[i].set_xlabel('Predicted Labels')
    axes[i].set_ylabel('True Labels')

plt.tight_layout()
plt.show()

"""Penjelasan model development :

1. **Random Forest**

* **Accuracy = 0.801887**: Model ini memiliki akurasi sekitar 80.19%, yang berarti bahwa sekitar 80.19% dari prediksi model benar (baik positif maupun negatif).
* **Precision = 0.400000**: Precision mengukur proporsi prediksi positif yang benar. Artinya, dari semua prediksi yang dibuat oleh model sebagai positif, hanya 40% yang benar-benar positif.
* **Recall = 0.333333**: Recall mengukur proporsi dari kasus positif yang berhasil diprediksi dengan benar oleh model. Artinya, model hanya berhasil menangkap sekitar 33% dari semua kasus positif yang ada.
* **F1-Score = 0.363636**: F1-Score adalah rata-rata harmonis antara precision dan recall. F1-Score yang rendah menunjukkan bahwa model belum mampu menyeimbangkan antara precision dan recall secara baik.

2. **CatBoost**

* **Accuracy = 0.797170**: Akurasi model CatBoost adalah sekitar 79.72%, sedikit lebih rendah dibandingkan Random Forest.
* **Precision = 0.387097**: Precision yang sedikit lebih rendah dibandingkan Random Forest (38.71%), artinya CatBoost sedikit kurang tepat dalam memprediksi positif dibandingkan Random Forest.
* **Recall = 0.333333**: Recall tetap sama dengan Random Forest (33.33%), yang menunjukkan bahwa CatBoost juga menangkap sekitar 33% kasus positif yang ada.
* **F1-Score = 0.358209**: F1-Score sedikit lebih baik dibandingkan Random Forest, meskipun masih menunjukkan performa yang kurang memadai.

3. **LightGBM**

* **Accuracy = 0.806604**: LightGBM memiliki akurasi tertinggi di antara ketiga model, yaitu sekitar 80.66%.
* **Precision = 0.407407**: Precision LightGBM adalah yang tertinggi (40.74%), menunjukkan bahwa lebih banyak prediksi positif yang benar dibandingkan dengan dua model lainnya.
* **Recall = 0.305556**: Recall LightGBM sedikit lebih rendah dari kedua model lainnya (30.56%), artinya model ini lebih sedikit dalam menangkap kasus positif.
* **F1-Score = 0.349206**: F1-Score LightGBM juga lebih baik dari kedua model lainnya, meskipun tetap menunjukkan performa yang perlu perbaikan.

Ringkasan:

* **Akurasi**: LightGBM sedikit lebih baik daripada dua model lainnya.
* **Precision**: LightGBM memiliki precision terbaik, artinya lebih banyak prediksi positif yang benar.
* **Recall**: Semua model memiliki recall yang rendah (sekitar 33%), menunjukkan bahwa model kurang efektif dalam menangkap kasus positif.
* **F1-Score**: LightGBM juga memiliki F1-Score terbaik, tetapi masih menunjukkan ruang untuk perbaikan, terutama dalam hal recall.

Secara keseluruhan, **LightGBM** cenderung lebih baik dalam hal akurasi dan precision, namun masih perlu perbaikan pada recall dan F1-Score untuk mencapai keseimbangan yang lebih baik antara recall dan precision.

"""

lgb_model = trained_models["LightGBM"]
importances_lgb = lgb_model.feature_importances_

importance_df_lgb = pd.DataFrame({
    'Feature': X_train_selected.columns,
    'Importance': importances_lgb
}).sort_values(by='Importance', ascending=False)

# Visualisasi
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df_lgb.head(15), palette="Oranges_r")
plt.title("Feature Importance - LightGBM")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

importance_df_lgb

# model LightGBM
lgb_model = lgb.LGBMClassifier(random_state=42, num_leaves=31, learning_rate=0.05, n_estimators=100, verbose=-1)
lgb_model.fit(X_train_selected, y_train_smote)

joblib.dump(lgb_model, 'lgb_model.pkl')

# Fitur
categorical_features = ['OverTime', 'JobRole', 'MaritalStatus', 'BusinessTravel', 'Department']
numerical_features = ['TotalWorkingYears', 'Age', 'JobLevel', 'StockOptionLevel',
                      'MonthlyIncome', 'YearsInCurrentRole', 'YearsWithCurrManager',
                      'JobInvolvement', 'YearsAtCompany', 'YearsSinceLastPromotion']

# Preprocessor
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(drop='first'), categorical_features)
])

# Buat pipeline: preprocessing + model
lgb_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', lgb.LGBMClassifier(eval_metric='logloss', random_state=42, learning_rate=0.05))
])

target = 'Attrition'
X = df_cleaned.drop(columns=target)
y = df_cleaned[target]

# split data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# fit pipeline
lgb_pipeline.fit(X_train, y_train)

# Prediksi data baru (bisa ambil data yang ingin diprediksi)
df_predict = df_cleaned[df_cleaned['Attrition'] != 1]

X_new = df_predict.drop(columns=target)
y_new = df_predict[target]

# Prediksi dan probabilitas
y_pred = lgb_pipeline.predict(X_new)
y_proba = lgb_pipeline.predict_proba(X_new)[:, 1]

# Hasil akhir
result_df = df_predict.copy()
result_df["Attrition (Actual)"] = y_new.values
result_df["PredictedAttrition"] = y_pred
result_df["Risk (Probability)"] = y_proba

# Evaluasi jika mau
accuracy = (y_new.values == y_pred).mean()
print(f"Akurasi prediksi: {accuracy:.4f}")
result_df.head(20)

"""**Kesimpulan**

Pada proyek ini, analisis data telah dilakukan untuk mengidentifikasi faktor-faktor yang mempengaruhi angka **Attrition** (keluar atau resign) karyawan di perusahaan **Jaya Jaya Maju**. Selain itu, model juga telah dilatih untuk memprediksi kemungkinan karyawan melakukan **attrition**.

### 1. **Faktor-faktor yang Mempengaruhi Attrition**

* **Overtime**
  Karyawan yang sering bekerja lembur cenderung memiliki kemungkinan yang lebih tinggi untuk meninggalkan perusahaan.

* **JobRole**
  Posisi atau departemen tertentu menunjukkan tingkat **attrition** yang lebih tinggi dibandingkan dengan posisi lainnya.

* **MaritalStatus**
  Status pernikahan karyawan turut mempengaruhi tingkat **attrition**, meskipun tidak sebesar faktor lainnya. Data menunjukkan bahwa karyawan yang sudah menikah memiliki tingkat **attrition** tertinggi.

* **Total Working Year**
  Pengalaman kerja total menunjukkan korelasi negatif terhadap **attrition**. Karyawan dengan pengalaman kerja lebih banyak cenderung lebih stabil, memiliki loyalitas yang lebih tinggi, dan lebih terbiasa dengan lingkungan organisasi. Mereka juga telah melewati fase pencarian kerja yang lebih awal.

* **Age**
  Karyawan yang lebih tua lebih cenderung lebih stabil dan jarang mengundurkan diri dibandingkan dengan karyawan yang lebih muda.

* **JobLevel, MonthlyIncome, StockOptionLevel**
  Jabatan, pendapatan bulanan, dan opsi saham berperan penting dalam kemungkinan karyawan bertahan. Karyawan dengan jabatan lebih tinggi, pendapatan lebih besar, dan opsi saham yang lebih baik cenderung memiliki insentif finansial dan emosional yang lebih kuat untuk tetap tinggal.

### 2. **Pelatihan Model Prediksi**

Model yang diuji untuk memprediksi **attrition** menunjukkan performa yang cukup baik. Berdasarkan metrik evaluasi seperti **accuracy**, **precision**, **recall**, dan **f1-score**, hasil model yang diuji adalah sebagai berikut:

| Model             | Accuracy | Precision | Recall   | F1-Score |
| ----------------- | -------- | --------- | -------- | -------- |
| **Random Forest** | 0.801887 | 0.400000  | 0.333333 | 0.363636 |
| **CatBoost**      | 0.797170 | 0.387097  | 0.333333 | 0.358209 |
| **LightGBM**      | 0.806604 | 0.407407  | 0.305556 | 0.349206 |

**Insight**:

* **LightGBM** memberikan hasil terbaik dengan **accuracy** 0.806604 dan **precision** 0.407407, meskipun **Random Forest** memiliki kinerja yang hampir sebanding dan sedikit lebih baik dalam **f1-score**.
* Meskipun semua model menunjukkan hasil yang cukup baik, **LightGBM** dapat dipertimbangkan sebagai model terbaik untuk prediksi **attrition**, berdasarkan **accuracy** dan **precision** yang lebih tinggi.

Berdasarkan analisis ini, model **LightGBM** dapat digunakan untuk memprediksi **attrition** secara lebih efektif, dengan fokus pada fitur-fitur yang telah diidentifikasi sebagai faktor penting.

# Export Data untuk Metabase Dashboard
"""

importance_df_lgb.to_csv("feature_importance.csv", index=False)

df_cleaned.to_csv("data_cleaned.csv", index=False)

result_df.to_csv("data_cleaned_predictive.csv", index=False)

!pip install pandas sqlalchemy

# pip freeze > requirements.txt

# from sqlalchemy import create_engine

# URL = [link-disupabase]
# engine = create_engine(URL)


# try:
#   importance_df_lgb.to_sql('important_feature', engine, if_exists='replace', index=False)
#   print("Data berhasil diunggah ke tabel 'important_feature'!")
#   df_cleaned.to_sql('cleaned_data', engine, if_exists='replace', index=False)
#   print("Data berhasil diunggah ke tabel 'cleaned_data'!")
#   result_df.to_sql('prediction_data', engine, if_exists='replace', index=False)
#   print("Data berhasil diunggah ke tabel 'prediction_data'!")
# except Exception as e:
#   print(f"Error saat mengunggah data: {e}")